{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkQUzr4D0Z5Q"
   },
   "source": [
    "#***Setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mu5tvllAZIh-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEEUI20_0uBX",
    "outputId": "939248ce-ed5f-4590-8a25-fe15e42b60cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIEgZEXW0vJ-"
   },
   "source": [
    "#***Reading trainning and validation data (train/val_data/labels)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYn3pnOk0S4x",
    "outputId": "82b00a44-91a7-483a-cfe3-321f87bce062"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path='drive/MyDrive/CS505/CS505-Final/'\n",
    "path='../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75fC1Mxy1fwv",
    "outputId": "f1dba525-7333-4d07-8e3b-a581757a62d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "eng_path=path+'data/2017_English_final/GOLD/Subtask_A/'\n",
    "train_file=[]\n",
    "val_file=[]\n",
    "\n",
    "for root, dirs, files in os.walk(eng_path):\n",
    "    for file_name in files:\n",
    "        if 'train' in file_name and '.txt' in file_name:\n",
    "            train_file.append(os.path.join(eng_path, file_name))\n",
    "        if 'dev' in file_name and '.txt' in file_name:\n",
    "            val_file.append(os.path.join(eng_path, file_name))\n",
    "print(train_file)\n",
    "print(val_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FiY5Jymc3Py8"
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "for file_path in train_file:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            train_data.append(entries[2])\n",
    "            train_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "    \n",
    "for file_path in val_file:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            val_data.append(entries[2])\n",
    "            val_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "val_data = np.array(val_data)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oew-bm4crSWB"
   },
   "source": [
    "#***Tokenize***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtNYpHuctfvm"
   },
   "source": [
    "###Get tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zI3Zg62orcZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (2020.10.28)\n",
      "Requirement already satisfied: requests in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/numpy-1.19.4-py3.8-linux-x86_64.egg (from transformers) (1.19.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: filelock in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from packaging>=20.0->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.6/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "2c66114b05a14b22bcf52995b34592ef",
      "d49e800b824a44339dfe8bd9d468333d",
      "0cadcf79416c4b64ac8284ce30dc3db3",
      "d73eb68eacb14250a9753072977a7309",
      "33072c75029c489893e29e5b3d0c08fd",
      "d01fae12c90448c59c3fba521978c6cb",
      "01a6ce2db2994050832699ce4361365a",
      "adee9999da8d426a82dca045869e6797",
      "52d5b37dd1174f31bc31d60c4d4e59f3",
      "d4bfc0f50f42475dbca408b682fd83e0",
      "722b09384830493c9371feaf013be12b",
      "ae01601506e748f0b4596975aa92e7b2",
      "c6f3bf3e16b24c9ba02b088cd974e01f",
      "6406ca5a30ec490ea7748bd4020f7611",
      "5c892c5429d44b8297e5859d56a84021",
      "3d42e8e739c6474aa3f9dd9540ce3846",
      "2424865829d743309c8c155b08a2dc2f",
      "2e796f5dd71b4d958f26d268c022fbac",
      "8d05959469d34a88b856a5c40c1b891b",
      "bedf651ef54b4bb3a4945d3fc54b33d4",
      "c39c1e55ace64b36a69dc143996b2034",
      "4d84acb714a443348cb8aaea381b006d",
      "1dd0678549894b1f9d0470acc81e7354",
      "5d35d5b7654f4a96ba9e1d19ff78bb69",
      "ecba63eec9714175a734bcb5d801da26",
      "46a3f6125f104f3987b5af32f9b5ad36",
      "14c1ca7f2d614206a97317d5ffd7cca9",
      "5ef89c34cb9c4424bce8563c581cd304",
      "7194473635dc48a69f87762732582aca",
      "ad297fe61f10446988afbd6cbd9455f2",
      "6ce09ca2ab354cc3b28aeefe04a31abb",
      "14b92448d70b4138a6585c09833e66c1",
      "2be33d3064924d7da4fc181fc10274bd"
     ]
    },
    "id": "0ZD-yw38rXZN",
    "outputId": "01d10ac4-d3b2-44af-9f01-7d9aabecc852"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfJs1RQAtjWt"
   },
   "source": [
    "###Find max length of train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6pe59ustBhj",
    "outputId": "a97dd667-8483-470b-9119-5b1e65757a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  118\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in train_data:\n",
    "\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-5n_ws1tpyF",
    "outputId": "a050c210-8d86-4d6a-b720-9936fbe9ba22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  114\n"
     ]
    }
   ],
   "source": [
    "max_len_val = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in val_data:\n",
    "\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_val = max(max_len_val, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLg17bqBt1YE"
   },
   "source": [
    "###Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UNylHyBhtRZf"
   },
   "outputs": [],
   "source": [
    "def tokenize(d,l):\n",
    "  input_ids=[]\n",
    "  attention_masks = []\n",
    "  # For every sentence...\n",
    "  for sent in d:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len+100,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "  # Convert the lists into tensors.\n",
    "  input_ids = torch.cat(input_ids, dim=0)\n",
    "  attention_masks = torch.cat(attention_masks, dim=0)\n",
    "  label = torch.tensor(l)\n",
    "  return input_ids,attention_masks,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oSOHNu5vWyn",
    "outputId": "d441e5af-ca5e-4d87-c3a2-d55e912ca60e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr4/cs523/tengzi/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_input_ids, train_attention_masks,train_label=tokenize(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-MrfNK9urON",
    "outputId": "a00ff45c-cb52-41ce-f77d-b32c88430151"
   },
   "outputs": [],
   "source": [
    "val_input_ids, val_attention_masks, val_label=tokenize(val_data,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_pC4zl4kvwX2",
    "outputId": "004f870f-ee45-4a0b-aa45-96b2fdc8b902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  I forgot how sad the first episode of the 5th season of Dexter is. #depressing #dexter #darkpassenger\n",
      "\n",
      "Token IDs: tensor([    0,    87,   100,  9904,  3642, 17110,    70,  5117, 50094,   111,\n",
      "           70,   190,   927, 34003,   111,   262,   425,   720,    83,     5,\n",
      "          468,   112, 11856,   214,   468, 39659,   720,   468,  1506,    92,\n",
      "        70154,  1505,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1])\n",
      "<s> I forgot how sad the first episode of the 5th season of Dexter is. #depressing #dexter #darkpassenger</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "print('Original: ', train_data[0])\n",
    "print('Token IDs:', train_input_ids[0])\n",
    "print(tokenizer.decode(train_input_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_9sZdJCwKGB"
   },
   "source": [
    "###Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p2hQOqlswNKA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_label)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Q-R9weM6wiV8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKBk7nb6xIjJ"
   },
   "source": [
    "#***Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XHZl13OzxP-G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM,XLMRobertaForSequenceClassification\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\",\n",
    "                                             num_labels = 3,\n",
    "                                             output_attentions = False,\n",
    "                                             output_hidden_states = False, \n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w416uBryx3KO",
    "outputId": "50de116c-8698-433d-817d-fbfac0959d79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr4/cs523/tengzi/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "okBV_jJEyIYq"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "npUVAX9WyJjX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "MgO-OKybyMxL",
    "outputId": "e5dd1922-8200-40e6-9424-8843cd131222",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  1,011.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,011.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,011.    Elapsed: 0:00:27.\n",
      "  Batch   160  of  1,011.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  1,011.    Elapsed: 0:00:46.\n",
      "  Batch   240  of  1,011.    Elapsed: 0:00:55.\n",
      "  Batch   280  of  1,011.    Elapsed: 0:01:04.\n",
      "  Batch   320  of  1,011.    Elapsed: 0:01:14.\n",
      "  Batch   360  of  1,011.    Elapsed: 0:01:23.\n",
      "  Batch   400  of  1,011.    Elapsed: 0:01:32.\n",
      "  Batch   440  of  1,011.    Elapsed: 0:01:41.\n",
      "  Batch   480  of  1,011.    Elapsed: 0:01:51.\n",
      "  Batch   520  of  1,011.    Elapsed: 0:02:00.\n",
      "  Batch   560  of  1,011.    Elapsed: 0:02:09.\n",
      "  Batch   600  of  1,011.    Elapsed: 0:02:18.\n",
      "  Batch   640  of  1,011.    Elapsed: 0:02:28.\n",
      "  Batch   680  of  1,011.    Elapsed: 0:02:37.\n",
      "  Batch   720  of  1,011.    Elapsed: 0:02:46.\n",
      "  Batch   760  of  1,011.    Elapsed: 0:02:55.\n",
      "  Batch   800  of  1,011.    Elapsed: 0:03:04.\n",
      "  Batch   840  of  1,011.    Elapsed: 0:03:14.\n",
      "  Batch   880  of  1,011.    Elapsed: 0:03:23.\n",
      "  Batch   920  of  1,011.    Elapsed: 0:03:32.\n",
      "  Batch   960  of  1,011.    Elapsed: 0:03:41.\n",
      "  Batch 1,000  of  1,011.    Elapsed: 0:03:51.\n",
      "\n",
      "  Average training loss: 0.78\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.63\n",
      "  Validation Loss: 0.82\n",
      "  Validation took: 0:00:23\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  1,011.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,011.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,011.    Elapsed: 0:00:28.\n",
      "  Batch   160  of  1,011.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  1,011.    Elapsed: 0:00:46.\n",
      "  Batch   240  of  1,011.    Elapsed: 0:00:55.\n",
      "  Batch   280  of  1,011.    Elapsed: 0:01:04.\n",
      "  Batch   320  of  1,011.    Elapsed: 0:01:14.\n",
      "  Batch   360  of  1,011.    Elapsed: 0:01:23.\n",
      "  Batch   400  of  1,011.    Elapsed: 0:01:32.\n",
      "  Batch   440  of  1,011.    Elapsed: 0:01:41.\n",
      "  Batch   480  of  1,011.    Elapsed: 0:01:50.\n",
      "  Batch   520  of  1,011.    Elapsed: 0:02:00.\n",
      "  Batch   560  of  1,011.    Elapsed: 0:02:09.\n",
      "  Batch   600  of  1,011.    Elapsed: 0:02:18.\n",
      "  Batch   640  of  1,011.    Elapsed: 0:02:27.\n",
      "  Batch   680  of  1,011.    Elapsed: 0:02:36.\n",
      "  Batch   720  of  1,011.    Elapsed: 0:02:46.\n",
      "  Batch   760  of  1,011.    Elapsed: 0:02:55.\n",
      "  Batch   800  of  1,011.    Elapsed: 0:03:04.\n",
      "  Batch   840  of  1,011.    Elapsed: 0:03:13.\n",
      "  Batch   880  of  1,011.    Elapsed: 0:03:22.\n",
      "  Batch   920  of  1,011.    Elapsed: 0:03:32.\n",
      "  Batch   960  of  1,011.    Elapsed: 0:03:41.\n",
      "  Batch 1,000  of  1,011.    Elapsed: 0:03:50.\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.63\n",
      "  Validation Loss: 0.79\n",
      "  Validation took: 0:00:23\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  1,011.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,011.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,011.    Elapsed: 0:00:28.\n",
      "  Batch   160  of  1,011.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  1,011.    Elapsed: 0:00:46.\n",
      "  Batch   240  of  1,011.    Elapsed: 0:00:55.\n",
      "  Batch   280  of  1,011.    Elapsed: 0:01:04.\n",
      "  Batch   320  of  1,011.    Elapsed: 0:01:14.\n",
      "  Batch   360  of  1,011.    Elapsed: 0:01:23.\n",
      "  Batch   400  of  1,011.    Elapsed: 0:01:32.\n",
      "  Batch   440  of  1,011.    Elapsed: 0:01:41.\n",
      "  Batch   480  of  1,011.    Elapsed: 0:01:50.\n",
      "  Batch   520  of  1,011.    Elapsed: 0:02:00.\n",
      "  Batch   560  of  1,011.    Elapsed: 0:02:09.\n",
      "  Batch   600  of  1,011.    Elapsed: 0:02:18.\n",
      "  Batch   640  of  1,011.    Elapsed: 0:02:27.\n",
      "  Batch   680  of  1,011.    Elapsed: 0:02:36.\n",
      "  Batch   720  of  1,011.    Elapsed: 0:02:46.\n",
      "  Batch   760  of  1,011.    Elapsed: 0:02:55.\n",
      "  Batch   800  of  1,011.    Elapsed: 0:03:04.\n",
      "  Batch   840  of  1,011.    Elapsed: 0:03:13.\n",
      "  Batch   880  of  1,011.    Elapsed: 0:03:22.\n",
      "  Batch   920  of  1,011.    Elapsed: 0:03:32.\n",
      "  Batch   960  of  1,011.    Elapsed: 0:03:41.\n",
      "  Batch 1,000  of  1,011.    Elapsed: 0:03:50.\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.64\n",
      "  Validation Loss: 0.96\n",
      "  Validation took: 0:00:23\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  1,011.    Elapsed: 0:00:09.\n",
      "  Batch    80  of  1,011.    Elapsed: 0:00:18.\n",
      "  Batch   120  of  1,011.    Elapsed: 0:00:28.\n",
      "  Batch   160  of  1,011.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  1,011.    Elapsed: 0:00:46.\n",
      "  Batch   240  of  1,011.    Elapsed: 0:00:55.\n",
      "  Batch   280  of  1,011.    Elapsed: 0:01:04.\n",
      "  Batch   320  of  1,011.    Elapsed: 0:01:14.\n",
      "  Batch   360  of  1,011.    Elapsed: 0:01:23.\n",
      "  Batch   400  of  1,011.    Elapsed: 0:01:32.\n",
      "  Batch   440  of  1,011.    Elapsed: 0:01:41.\n",
      "  Batch   480  of  1,011.    Elapsed: 0:01:51.\n",
      "  Batch   520  of  1,011.    Elapsed: 0:02:00.\n",
      "  Batch   560  of  1,011.    Elapsed: 0:02:09.\n",
      "  Batch   600  of  1,011.    Elapsed: 0:02:18.\n",
      "  Batch   640  of  1,011.    Elapsed: 0:02:27.\n",
      "  Batch   680  of  1,011.    Elapsed: 0:02:37.\n",
      "  Batch   720  of  1,011.    Elapsed: 0:02:46.\n",
      "  Batch   760  of  1,011.    Elapsed: 0:02:55.\n",
      "  Batch   800  of  1,011.    Elapsed: 0:03:04.\n",
      "  Batch   840  of  1,011.    Elapsed: 0:03:13.\n",
      "  Batch   880  of  1,011.    Elapsed: 0:03:23.\n",
      "  Batch   920  of  1,011.    Elapsed: 0:03:32.\n",
      "  Batch   960  of  1,011.    Elapsed: 0:03:41.\n",
      "  Batch 1,000  of  1,011.    Elapsed: 0:03:50.\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:03:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.64\n",
      "  Validation Loss: 1.03\n",
      "  Validation took: 0:00:23\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:17:03 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0:03:53</td>\n",
       "      <td>0:00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0:03:53</td>\n",
       "      <td>0:00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0:03:53</td>\n",
       "      <td>0:00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.34</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0:03:53</td>\n",
       "      <td>0:00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.78         0.82           0.63       0:03:53         0:00:23\n",
       "2               0.57         0.79           0.63       0:03:53         0:00:23\n",
       "3               0.44         0.96           0.64       0:03:53         0:00:23\n",
       "4               0.34         1.03           0.64       0:03:53         0:00:23"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvvpuOtLrG-q"
   },
   "source": [
    "#***Reading test data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Cv4F9xA_0kcw"
   },
   "outputs": [],
   "source": [
    "arabic_path=path+'data/2017_Arabic_train_final/GOLD/SemEval2017-task4-train.subtask-A.arabic.txt'\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "with open(arabic_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        entries = l.split('\\t')\n",
    "        test_data.append(entries[2])\n",
    "        test_labels.append(sentiment_to_label[entries[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3355"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrxTvLpRq_UP",
    "outputId": "57c4682f-0158-4da5-cdf1-07a922096a7f"
   },
   "outputs": [],
   "source": [
    "test_input_ids, test_attention_masks, test_label=tokenize(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = TensorDataset(test_input_ids, test_attention_masks, test_label)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 3,355 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.544\n"
     ]
    }
   ],
   "source": [
    "total_val_accuracy=0\n",
    "for i in range(len(predictions)):\n",
    "  total_val_accuracy += flat_accuracy(predictions[i], true_labels[i])\n",
    "\n",
    "avg_accuracy = total_val_accuracy / len(prediction_dataloader)\n",
    "print(\"  Accuracy: {0:.3f}\".format(avg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***test on translated***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_path=path+'data/2017_Arabic_train_final/GOLD/SemEval2017-task4-train.subtask-A.english.txt'\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "with open(trans_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        entries = l.split('\\t')\n",
    "        if len(entries) != 3:\n",
    "            entries = l.split(' ', maxsplit=2)\n",
    "        test_data.append(entries[2])\n",
    "        test_labels.append(sentiment_to_label[entries[1]])\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr4/cs523/tengzi/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_input_ids, test_attention_masks, test_label=tokenize(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = TensorDataset(test_input_ids, test_attention_masks, test_label)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 3,355 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.591\n"
     ]
    }
   ],
   "source": [
    "total_val_accuracy=0\n",
    "for i in range(len(predictions)):\n",
    "  total_val_accuracy += flat_accuracy(predictions[i], true_labels[i])\n",
    "\n",
    "avg_accuracy = total_val_accuracy / len(prediction_dataloader)\n",
    "print(\"  Accuracy: {0:.3f}\".format(avg_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_project_roberta.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01a6ce2db2994050832699ce4361365a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0cadcf79416c4b64ac8284ce30dc3db3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adee9999da8d426a82dca045869e6797",
      "max": 615,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52d5b37dd1174f31bc31d60c4d4e59f3",
      "value": 615
     }
    },
    "14b92448d70b4138a6585c09833e66c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14c1ca7f2d614206a97317d5ffd7cca9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dd0678549894b1f9d0470acc81e7354": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d35d5b7654f4a96ba9e1d19ff78bb69",
       "IPY_MODEL_ecba63eec9714175a734bcb5d801da26",
       "IPY_MODEL_46a3f6125f104f3987b5af32f9b5ad36"
      ],
      "layout": "IPY_MODEL_14c1ca7f2d614206a97317d5ffd7cca9"
     }
    },
    "2424865829d743309c8c155b08a2dc2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2be33d3064924d7da4fc181fc10274bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c66114b05a14b22bcf52995b34592ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d49e800b824a44339dfe8bd9d468333d",
       "IPY_MODEL_0cadcf79416c4b64ac8284ce30dc3db3",
       "IPY_MODEL_d73eb68eacb14250a9753072977a7309"
      ],
      "layout": "IPY_MODEL_33072c75029c489893e29e5b3d0c08fd"
     }
    },
    "2e796f5dd71b4d958f26d268c022fbac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33072c75029c489893e29e5b3d0c08fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d42e8e739c6474aa3f9dd9540ce3846": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46a3f6125f104f3987b5af32f9b5ad36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14b92448d70b4138a6585c09833e66c1",
      "placeholder": "",
      "style": "IPY_MODEL_2be33d3064924d7da4fc181fc10274bd",
      "value": " 8.68M/8.68M [00:00&lt;00:00, 32.6MB/s]"
     }
    },
    "4d84acb714a443348cb8aaea381b006d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52d5b37dd1174f31bc31d60c4d4e59f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c892c5429d44b8297e5859d56a84021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c39c1e55ace64b36a69dc143996b2034",
      "placeholder": "",
      "style": "IPY_MODEL_4d84acb714a443348cb8aaea381b006d",
      "value": " 4.83M/4.83M [00:00&lt;00:00, 22.2MB/s]"
     }
    },
    "5d35d5b7654f4a96ba9e1d19ff78bb69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ef89c34cb9c4424bce8563c581cd304",
      "placeholder": "",
      "style": "IPY_MODEL_7194473635dc48a69f87762732582aca",
      "value": "Downloading: 100%"
     }
    },
    "5ef89c34cb9c4424bce8563c581cd304": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6406ca5a30ec490ea7748bd4020f7611": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d05959469d34a88b856a5c40c1b891b",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bedf651ef54b4bb3a4945d3fc54b33d4",
      "value": 5069051
     }
    },
    "6ce09ca2ab354cc3b28aeefe04a31abb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7194473635dc48a69f87762732582aca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "722b09384830493c9371feaf013be12b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d05959469d34a88b856a5c40c1b891b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad297fe61f10446988afbd6cbd9455f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adee9999da8d426a82dca045869e6797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae01601506e748f0b4596975aa92e7b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6f3bf3e16b24c9ba02b088cd974e01f",
       "IPY_MODEL_6406ca5a30ec490ea7748bd4020f7611",
       "IPY_MODEL_5c892c5429d44b8297e5859d56a84021"
      ],
      "layout": "IPY_MODEL_3d42e8e739c6474aa3f9dd9540ce3846"
     }
    },
    "bedf651ef54b4bb3a4945d3fc54b33d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c39c1e55ace64b36a69dc143996b2034": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6f3bf3e16b24c9ba02b088cd974e01f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2424865829d743309c8c155b08a2dc2f",
      "placeholder": "",
      "style": "IPY_MODEL_2e796f5dd71b4d958f26d268c022fbac",
      "value": "Downloading: 100%"
     }
    },
    "d01fae12c90448c59c3fba521978c6cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d49e800b824a44339dfe8bd9d468333d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d01fae12c90448c59c3fba521978c6cb",
      "placeholder": "",
      "style": "IPY_MODEL_01a6ce2db2994050832699ce4361365a",
      "value": "Downloading: 100%"
     }
    },
    "d4bfc0f50f42475dbca408b682fd83e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d73eb68eacb14250a9753072977a7309": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4bfc0f50f42475dbca408b682fd83e0",
      "placeholder": "",
      "style": "IPY_MODEL_722b09384830493c9371feaf013be12b",
      "value": " 615/615 [00:00&lt;00:00, 6.08kB/s]"
     }
    },
    "ecba63eec9714175a734bcb5d801da26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad297fe61f10446988afbd6cbd9455f2",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ce09ca2ab354cc3b28aeefe04a31abb",
      "value": 9096718
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
